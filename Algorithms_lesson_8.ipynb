{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для любой модели из курса(кроме KNN) и данных на которых она строилась: примнить метод главных компонент к данным, и сравнить работу модели на исходных данных с работой на данных где в качестве признаков используются две главные компоненты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем модель градиентного бустинга на деревьях решений. \n",
    "\n",
    "Следующие 5 ячеек - код с урока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn import model_selection\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_predict(X, trees_list, coef_list, eta):\n",
    "    # Реализуемый алгоритм градиентного бустинга будет инициализироваться нулевыми значениями,\n",
    "    # поэтому все деревья из списка trees_list уже являются дополнительными и \n",
    "    #при предсказании прибавляются с шагом eta\n",
    "    return np.array([sum(((1 if i==0 else eta)* coef * alg.predict([x])[0] \n",
    "                          for i, (alg, coef) in enumerate(zip(trees_list, coef_list)))) \n",
    "                     for x in X])\n",
    "\n",
    "\n",
    "def mean_squared_error(y_real, prediction):\n",
    "    return (sum((y_real - prediction)**2)) / len(y_real)\n",
    "\n",
    "\n",
    "def bias(y, z):\n",
    "    return (y - z)\n",
    "\n",
    "\n",
    "def gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        tree = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree.fit(X_train, y_train)\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = gb_predict(X_train, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree.fit(X_train, bias(y_train, target))\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число деревьев в ансамбле\n",
    "n_trees = 10\n",
    "\n",
    "# для простоты примем коэффициенты равными 1\n",
    "coefs = [1] * n_trees\n",
    "\n",
    "# Максимальная глубина деревьев\n",
    "max_depth = 3\n",
    "\n",
    "# Шаг\n",
    "eta = 0.05\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка алгоритма из 10 деревьев глубиной 3     с шагом 0.05 на тренировочной выборке: 2730.2939022043424\n",
      "Ошибка алгоритма из 10 деревьев глубиной 3     с шагом 0.05 на тестовой выборке: 3536.635095765551\n"
     ]
    }
   ],
   "source": [
    "def evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta):\n",
    "    train_prediction = gb_predict(X_train, trees, coefs, eta)\n",
    "\n",
    "    print(f'Ошибка алгоритма из {n_trees} деревьев глубиной {max_depth} \\\n",
    "    с шагом {eta} на тренировочной выборке: {mean_squared_error(y_train, train_prediction)}')\n",
    "\n",
    "    test_prediction = gb_predict(X_test, trees, coefs, eta)\n",
    "\n",
    "    print(f'Ошибка алгоритма из {n_trees} деревьев глубиной {max_depth} \\\n",
    "    с шагом {eta} на тестовой выборке: {mean_squared_error(y_test, test_prediction)}')\n",
    "evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метод главных компонент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X_train, X_test, num=2): # задаем кол-во главных компонент\n",
    "    X = X_train.astype(float)\n",
    "    mean=np.apply_along_axis(np.mean, 0, X)\n",
    "    std=np.apply_along_axis(np.std, 0, X)\n",
    "    X_normed_train=(X-mean[np.newaxis, :])/std[np.newaxis, :]\n",
    "    X_normed_test=(X_test-mean[np.newaxis, :])/std[np.newaxis, :]\n",
    "    \n",
    "    # Найдем собственные векторы и собственные значения \n",
    "    covariance_matrix = X_normed_train.T.dot(X_normed_train)\n",
    "    eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "    # сформируем список кортежей (собственное значение, собственный вектор)\n",
    "    eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
    "\n",
    "    # и отсортируем список по убыванию собственных значений\n",
    "    eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Сформируем вектор весов из собственных векторов, соответствующих первым двум главным компонентам\n",
    "    W = eig_pairs[0][1].reshape(X.shape[1],1)\n",
    "    for i in range(1, num):\n",
    "        W = np.hstack((W, eig_pairs[i][1].reshape(X.shape[1],1)))\n",
    "    print(f'Матрица весов W:\\n', W)\n",
    "    \n",
    "    return X_normed_train.dot(W), X_normed_test.dot(W)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица весов W:\n",
      " [[-0.21733032 -0.19995957]\n",
      " [-0.18502792  0.36896673]\n",
      " [-0.30467229  0.10274987]\n",
      " [-0.2674335   0.0261983 ]\n",
      " [-0.35117579 -0.5387591 ]\n",
      " [-0.36202134 -0.39797817]\n",
      " [ 0.27567002 -0.57589296]\n",
      " [-0.42412513  0.15330275]\n",
      " [-0.37272103  0.06823572]\n",
      " [-0.32404535  0.06463192]]\n"
     ]
    }
   ],
   "source": [
    "new_X_train, new_X_test = pca(X_train, X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка алгоритма из 10 деревьев глубиной 3     с шагом 0.05 на тренировочной выборке: 3381.9390300975506\n",
      "Ошибка алгоритма из 10 деревьев глубиной 3     с шагом 0.05 на тестовой выборке: 4369.338581952493\n"
     ]
    }
   ],
   "source": [
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, new_X_train, new_X_test, y_train, y_test, coefs, eta)\n",
    "evaluate_alg(new_X_train, new_X_test, y_train, y_test, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Двух главных компонент не хватает, модель на исходных данных работает лучше, чем при использовании 2х главных компонент. Наилучшие результаты достигаются при использовании 4 главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
